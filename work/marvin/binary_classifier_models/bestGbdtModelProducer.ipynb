{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# <api>\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn import metrics #Additional scklearn functions\n",
    "from sklearn.ensemble import GradientBoostingClassifier #GBM modelorithm\n",
    "from sklearn.grid_search import GridSearchCV #Perforing grid search\n",
    "\n",
    "import work.marvin.binary_classifier_models.modelfit as modelfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# <api>\n",
    "def bestModelProducer(df, target, datamapper, fig_path):    \n",
    "    \"\"\"\n",
    "    # auto GBDT model generation, 3 steps:\n",
    "    1. estimate optimal model parameters space for gridsearch, depends on sample size and feature size\n",
    "    2. run gridsearch to find best parameter set\n",
    "    3. train the best GBDT model using the best parameter set\n",
    "    \"\"\"\n",
    "    traindf, testdf = modelfit.prepareDataforTraining(df, datamapper)\n",
    "    train_array = datamapper.transform(traindf)\n",
    "    train = train_array[:, :-1] \n",
    "    # estimate optimal parameters grid space\n",
    "    param_grid1, param_grid2 = parameterGridInitialization(train)\n",
    "    bestModel, accuracy, auc, cv_score = produceBestGBMmodel(traindf, testdf, datamapper, param_grid1, param_grid2, fig_path)\n",
    "    return bestModel, traindf, testdf, accuracy, auc, cv_score\n",
    "\n",
    "\n",
    "def initializationGridSearch(df, datamapper):\n",
    "    \"\"\"\n",
    "     根据特征数量、样本数量初始化GBM参数空间\n",
    "    \"\"\"\n",
    "    traindf, testdf = modelfit.prepareDataforTraining(df, datamapper)  \n",
    "    train_array = datamapper.transform(traindf)\n",
    "    train = train_array[:, :-1] \n",
    "    # estimate optimal parameters grid space\n",
    "    param_grid1, param_grid2 = parameterGridInitialization(train)\n",
    "\n",
    "\n",
    "def produceBestGBMmodel(traindf, testdf, datamapper, param_grid1, param_grid2, fig_path=None):\n",
    "    # datamapper transform\n",
    "    train_array = datamapper.transform(traindf)\n",
    "    train = train_array[:, :-1]\n",
    "    labels_train = train_array[:, -1]\n",
    "\n",
    "    test_array = datamapper.transform(testdf)\n",
    "    test = test_array[:, :-1]\n",
    "    labels_test = test_array[:, -1]\n",
    "\n",
    "    # running grid search to get the best parameter set  \n",
    "    best_subsample, best_estimators, best_learning_rate, best_max_depth, best_max_feature, best_min_samples_split = gbmGridSearch(train,\n",
    "                                                                                                                                  labels_train,\n",
    "                                                                                                                                  param_grid1,\n",
    "                                                                                                                                  param_grid2)\n",
    "\n",
    "    # train a gbm using the best parameter set\n",
    "    gbm_best = GradientBoostingClassifier(learning_rate=best_learning_rate,\n",
    "                                          n_estimators=best_estimators,\n",
    "                                          max_depth=best_max_depth,\n",
    "                                          min_samples_split=best_min_samples_split,\n",
    "                                          subsample=best_subsample,\n",
    "                                          max_features=best_max_feature,\n",
    "                                          random_state=10)\n",
    "\n",
    "    alg, train_predictions, train_predprob, cv_score = modelfit.modelfit(gbm_best, datamapper, train, labels_train, test, labels_test,\n",
    "                                                                         fig_path=fig_path)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(labels_train, train_predictions)\n",
    "    auc = metrics.roc_auc_score(labels_train, train_predprob)\n",
    "    cv_score = [np.mean(cv_score), np.std(cv_score), np.min(cv_score), np.max(cv_score)]\n",
    "\n",
    "    return alg, accuracy, auc, cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# <api>\n",
    "def n_estimators_space(train_size):\n",
    "    if train_size > 2000:\n",
    "        n_estimators_spc = range(50,301,20)\n",
    "    else :\n",
    "        n_estimators_spc = range(20,100,10)\n",
    "    return n_estimators_spc\n",
    "\n",
    "\n",
    "def min_samples_split_space(train_size):\n",
    "    if train_size > 20000 :\n",
    "        min_samples_split = range(500,3001,200)\n",
    "    else :\n",
    "        min_samples_split = range(min(train_size, 100), min(train_size, 1001),100)     \n",
    "    return min_samples_split\n",
    "\n",
    "\n",
    "def max_feature_space(feature_size):\n",
    "    fs_sqrt = math.sqrt(feature_size) \n",
    "    if fs_sqrt > 10 :\n",
    "        max_feature = range(int(fs_sqrt-3), int(fs_sqrt*1.50), 2)\n",
    "    else :\n",
    "        max_feature = range(int(fs_sqrt), int(fs_sqrt*1.50), 2)    \n",
    "    return max_feature\n",
    "\n",
    "def max_depth_space(feature_size):\n",
    "    if feature_size > 1000 :\n",
    "        max_depth = range(5,14,2)\n",
    "    else :\n",
    "        max_depth = range(3,10,2)      \n",
    "    return max_depth\n",
    "\n",
    "\n",
    "def parameterGridInitialization(trainX):\n",
    "    feature_size = trainX.shape[1]-1  \n",
    "    train_size = trainX.shape[0]\n",
    "    \n",
    "    subsample_spc = [0.6, 0.7, 0.8, 0.9]\n",
    "    learning_rate_spc = [0.01,0.05,0.1]\n",
    "    n_estimators_spc = n_estimators_space(train_size)\n",
    "    min_samples_split_spc = min_samples_split_space(train_size) \n",
    "    max_feature_spc = max_feature_space(feature_size)\n",
    "    max_depth_spc = max_depth_space(feature_size)\n",
    "    min_samples_split_spc = min_samples_split_space(train_size)\n",
    "\n",
    "    # most important parameters    \n",
    "    param_grid1 = {'subsample':subsample_spc, 'n_estimators':n_estimators_spc, 'learning_rate':learning_rate_spc}\n",
    "    # tree specific parameters\n",
    "    param_grid2 = {'max_depth':max_depth_spc, 'max_features':max_feature_spc, \n",
    "                   'min_samples_split': min_samples_split_spc}\n",
    "    \n",
    "    return param_grid1, param_grid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# <api>\n",
    "def gbmGridSearch(train, labels_train, param_grid1, param_grid2):\n",
    "    gsearch1 = GridSearchCV(estimator=GradientBoostingClassifier(min_samples_split=30,\n",
    "                                                                   max_features='sqrt',\n",
    "                                                                   max_depth = 5,\n",
    "                                                                   random_state=10), \n",
    "                            param_grid=param_grid1, scoring='roc_auc', n_jobs=4, iid=False, cv=5)\n",
    "    gsearch1.fit(train, labels_train)\n",
    "    \n",
    "    best_parameters = gsearch1.best_estimator_.get_params()\n",
    "    best_subsample = best_parameters[\"subsample\"]   \n",
    "    best_estimators = best_parameters['n_estimators']\n",
    "    best_learning_rate = best_parameters['learning_rate']\n",
    "\n",
    "    gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(subsample=best_subsample,\n",
    "                                                                   n_estimators=best_estimators,\n",
    "                                                                   learning_rate=best_learning_rate,\n",
    "                                                                   random_state=10), \n",
    "                            param_grid=param_grid2, scoring='roc_auc', n_jobs=4, iid=False, cv=5)\n",
    "    gsearch2.fit(train, labels_train)  \n",
    "    \n",
    "    best_parameters2 = gsearch2.best_estimator_.get_params()    \n",
    "    best_max_depth = best_parameters2[\"max_depth\"]\n",
    "    best_max_feature = best_parameters2[\"max_features\"]\n",
    "    best_min_samples_split = best_parameters2[\"min_samples_split\"]\n",
    "    \n",
    "    return best_subsample, best_estimators, best_learning_rate, best_max_depth, best_max_feature, best_min_samples_split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
